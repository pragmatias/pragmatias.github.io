<!doctype html><html lang=fr><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta charset=utf-8><meta name=robots content="noindex, nofollow, noarchive, nosnipper, noodp, noydir"><meta name=google content="notranslate, noimageindex"><meta name=slurp content="notranslate, noimageindex"><meta name=msnbot content="notranslate, noimageindex"><meta name=bingbot content="notranslate, noimageindex"><meta name=generator content="Hugo 0.129.0"><link rel=stylesheet href=https://www.pragmatias.fr//css/bootstrap.min.css><link rel=stylesheet href=https://www.pragmatias.fr//css/pragmatias.css><script src=https://www.pragmatias.fr//js/jquery-3.6.0.slim.min.js></script><script src=https://www.pragmatias.fr//js/popper.min.js></script><script src=https://www.pragmatias.fr//js/bootstrap.bundle.min.js></script><link rel=alternate type=application/rss+xml href=https://www.pragmatias.fr/feed.xml><title>LLMs : Utilisation de Ollama avec Podman et VS Code</title><body><div class="navbar navbar-expand-md prag-bg-primary prag-header" role=navigation><div class="container-fluid justify-content-center"><div class=navbar-brand><a href=https://www.pragmatias.fr/blog/><img src=/images/logo_pragmatias.svg alt=pragmatias></a></div><button class="navbar-toggler justify-content-end prag-navbar" type=button data-toggle=collapse data-target=#navbarSupportedContent1,#navbarSupportedContent2 aria-controls=navbarSupportedContent1 aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent1><ul class="navbar-nav text-center"><li class=nav-item><a class=nav-link href=https://www.pragmatias.fr/blog/>Blog</a></li><li class=nav-item><a class=nav-link href=https://www.pragmatias.fr/tags/>Tags</a></li><li class=nav-item><a class=nav-link href=https://www.pragmatias.fr/archives/>Archives</a></li></ul></div><div class="collapse navbar-collapse justify-content-md-end" id=navbarSupportedContent2><ul class="navbar-nav flex-row justify-content-center"><li class=nav-item><a href=https://www.pragmatias.fr/en/2024/07/24/llms-using-ollama-with-podman-and-vs-code/ class="prag_header_svg mr-1 ml-1"><img src=/images/united-kingdom-flag-round-xs-24.png alt=English></a></li><li class=nav-item><a href=https://www.pragmatias.fr/feed.xml title="Pragmatias Blog" class="prag_header_svg mr-1 ml-1"><svg height="24" style="enable-background:new 0 0 508.52 508.52" viewBox="0 0 508.52 508.52" width="24" xmlns:xlink="http://www.w3.org/1999/xlink"><path style="fill-rule:evenodd;clip-rule:evenodd;fill:" d="M254.26.0C113.845.0.0 113.845.0 254.26s113.845 254.26 254.26 254.26 254.26-113.845 254.26-254.26C508.52 113.813 394.675.0 254.26.0zM137.141 412.441c-22.852.0-41.413-18.434-41.413-41.285.0-22.693 18.561-41.349 41.413-41.349 22.915.0 41.444 18.656 41.476 41.349C178.618 393.976 160.088 412.441 137.141 412.441zM241.197 412.791c0-39.029-15.16-75.674-42.62-103.071-27.46-27.524-63.978-42.716-102.785-42.716V207.38c113.177.0 205.315 92.137 205.315 205.41h-59.91zM347.001 412.727c0-138.603-112.669-251.399-251.145-251.399v-59.624c171.435.0 310.96 139.589 310.96 311.023H347.001z"/></svg></a></li><li class=nav-item><a href=mailto:contact@pragmatias.fr title=Mail class="prag_header_svg mr-1 ml-1"><svg height="24" style="enable-background:new 0 0 299.997 299.997" viewBox="0 0 299.997 299.997" width="24" xmlns:xlink="http://www.w3.org/1999/xlink"><path style="fill-rule:evenodd;clip-rule:evenodd;fill:" d="M149.996.0C67.157.0.001 67.158.001 149.997c0 82.837 67.156 150 149.995 150s150-67.163 150-150C299.996 67.158 232.835.0 149.996.0zM149.999 52.686l88.763 55.35H61.236l88.763-55.35zm89.869 143.737h-.009c0 8.878-7.195 16.072-16.072 16.072H76.211c-8.878.0-16.072-7.195-16.072-16.072v-84.865c0-.939.096-1.852.252-2.749l84.808 52.883c.104.065.215.109.322.169.112.062.226.122.34.179.599.309 1.216.558 1.847.721.065.018.13.026.195.041.692.163 1.393.265 2.093.265h.005c.005.0.01.0.01.0.7.0 1.401-.099 2.093-.265.065-.016.13-.023.195-.041.63-.163 1.245-.412 1.847-.721.114-.057.228-.117.34-.179.106-.06.218-.104.322-.169l84.808-52.883c.156.897.252 1.808.252 2.749v84.865z"/></svg></a></li><li><a href=https://github.com/pragmatias/ title=github class="prag_header_svg mr-1 ml-1"><svg height="24" style="enable-background:new 0 0 438.549 438.549" viewBox="0 0 438.549 438.549" width="24" xmlns:xlink="http://www.w3.org/1999/xlink"><path style="fill-rule:evenodd;clip-rule:evenodd;fill:" d="M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8C295.736 15.166 259.057 5.365 219.271 5.365c-39.781.0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168.0 184.854.0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562.0-.571-.049-5.708-.144-15.417-.098-9.709-.144-18.179-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289s4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136s11.704-.476 16.274-1.423c4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826.0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817.0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906C438.536 184.851 428.728 148.168 409.132 114.573z"/></svg></a></li></ul></div></div></div><div id=content><div class=container-fluid><article class="blog-post blog-post-with-toc"><header><h2 class=blog-post-title>LLMs : Utilisation de Ollama avec Podman et VS Code</h2><div class=blog-post-date><span>Dernière modification : 24 Juillet 2024</span></div><div class=blog-post-date>Temps de lecture : 6 minute(s) - 1143 mots</div><div class=blog-post-tags><strong>Tags:</strong>
<a href=https://www.pragmatias.fr/tags/ollama/>Ollama</a>
<a href=https://www.pragmatias.fr/tags/llms/>LLMs</a>
<a href=https://www.pragmatias.fr/tags/vs-code/>VS Code</a>
<a href=https://www.pragmatias.fr/tags/podman/>Podman</a></div></header><aside class=prag-toc><h1 class=prag-toc-head>Sommaire</h1><div class=prag-toc-body><nav id=TableOfContents><ol><li><a href=#ollama>Ollama</a></li><li><a href=#podman>Podman</a></li><li><a href=#vs-code>VS Code</a><ol><li><a href=#installation-de-lextension>Installation de l&rsquo;extension</a></li><li><a href=#configuration-de-lextension-vs-code-continue>Configuration de l&rsquo;extension VS Code Continue</a></li></ol></li><li><a href=#configuration-locale>Configuration locale</a><ol><li><a href=#mise-en-place-de-ollama-en-locale>Mise en place de Ollama en locale</a></li><li><a href=#configuration-de-lextension-vs-code-continue-1>Configuration de l&rsquo;extension VS Code Continue</a></li></ol></li><li><a href=#configuration-distante>Configuration distante</a><ol><li><a href=#mise-en-place-de-ollama-avec-podman>Mise en place de Ollama avec Podman</a></li><li><a href=#configuration-de-lextension-vs-code-continue-2>Configuration de l&rsquo;extension VS Code Continue</a></li></ol></li><li><a href=#conclusion>Conclusion</a></li></ol></nav></div></aside><a id=showTopBtn href=# class=prag-sticky-bot><svg height="24" id="Layer_1" style="enable-background:new 0 0 438.533 438.533" viewBox="0 0 438.533 438.533" width="24" xmlns:xlink="http://www.w3.org/1999/xlink"><path style="fill-rule:evenodd;clip-rule:evenodd;fill:" d="M409.133 109.203c-19.608-33.592-46.205-60.189-79.798-79.796C295.736 9.801 259.058.0 219.273.0c-39.781.0-76.47 9.801-110.063 29.407-33.595 19.604-60.192 46.201-79.8 79.796C9.801 142.8.0 179.489.0 219.267c0 39.78 9.804 76.463 29.407 110.062 19.607 33.592 46.204 60.189 79.799 79.798 33.597 19.605 70.283 29.407 110.063 29.407s76.47-9.802 110.065-29.407c33.593-19.602 60.189-46.206 79.795-79.798 19.603-33.596 29.403-70.284 29.403-110.062C438.533 179.485 428.732 142.795 409.133 109.203zM361.449 231.831l-25.981 25.981c-3.613 3.613-7.901 5.42-12.847 5.42-4.948.0-9.229-1.807-12.847-5.42l-53.954-53.961v143.32c0 4.948-1.813 9.232-5.428 12.847-3.613 3.62-7.898 5.427-12.847 5.427h-36.547c-4.948.0-9.231-1.807-12.847-5.427-3.617-3.614-5.426-7.898-5.426-12.847v-143.32l-53.959 53.961c-3.431 3.425-7.708 5.133-12.85 5.133-5.14.0-9.423-1.708-12.85-5.133l-25.981-25.981c-3.422-3.429-5.137-7.714-5.137-12.852.0-5.137 1.709-9.419 5.137-12.847l103.356-103.353 25.981-25.981c3.427-3.425 7.71-5.14 12.847-5.14 5.142.0 9.423 1.715 12.849 5.14l25.98 25.981 103.35 103.353c3.432 3.427 5.14 7.71 5.14 12.847C366.589 224.117 364.881 228.402 361.449 231.831z"/></svg>
</a><script>$(document).ready(function(){$("#showTopBtn").removeClass("prag-sticky-bot"),$("#showTopBtn").addClass("prag-sticky-hide"),$(function(){$(window).scroll(function(){$(this).scrollTop()>900?($("#showTopBtn").addClass("prag-sticky-bot"),$("#showTopBtn").removeClass("prag-sticky-hide")):($("#showTopBtn").addClass("prag-sticky-hide"),$("#showTopBtn").removeClass("prag-sticky-bot"))})})})</script><div class=blog-post-main><p>Vous trouverez dans cet article, des informations pour utiliser <a href=https://ollama.com/>Ollama</a> (<a href=https://en.wikipedia.org/wiki/Large_language_model>LLMs</a>) avec <a href=https://podman.io/>Podman</a> et <a href=https://code.visualstudio.com/>VS Code</a>.</p><h1 id=ollama>Ollama</h1><p><a href=https://ollama.com/>Ollama</a> est un outil gratuit et open-source conçu pour exécuter localement des <a href=https://en.wikipedia.org/wiki/Large_language_model>LLMs (Large Language Models)</a> libre sur votre système.</p><p><a href=https://ollama.com/>Ollama</a> est conçu pour tirer avantage des cartes graphiques Nvidia ou AMD. Si vous n&rsquo;avez qu&rsquo;un CPU, vous aurez une très mauvaise performance du modèle.</p><p>Vous trouverez la liste des GPU prises en charge dans la <a href=https://github.com/ollama/ollama/blob/main/docs/gpu.md>documentation officielle</a>.</p><p>Il est nécessaire d&rsquo;avoir une quantité importante de mémoire pour l&rsquo;utiliser. Je vous recommande de disposer d&rsquo;au moins 32 Go.</p><p>Vous trouverez tous les modèles LLM disponibles dans la <a href=https://ollama.com/library>bibliothèque officielle</a>.</p><p>Quelques exemples de modèles disponibles :</p><ul><li><a href=https://ollama.com/library/llama3>llama3</a> : Meta Llama 3, une famille de modèles développée par Meta Inc.</li><li><a href=https://ollama.com/library/codellama>codellama</a> : Code Llama est un modèle conçu pour générer et discuter du code, construit sur la base de Llama 2.</li><li><a href=https://ollama.com/library/gemma2>gemma2</a> : Google Gemma 2, présentant une nouvelle architecture conçue pour offrir des performances et une efficacité exceptionnelles.</li><li><a href=https://ollama.com/library/codegemma>codegemma</a> : CodeGemma est un ensemble de modèles puissants et légers qui peuvent accomplir diverses tâches de codage, telles que la finition automatique du code, la génération de code, la compréhension naturelle du langage, la raison mathématique et l&rsquo;exécution d&rsquo;instructions.</li><li><a href=https://ollama.com/library/starcoder2>starcoder2</a> : StarCoder2 est la prochaine génération de modèles decode ouverts entraînés de manière transparente.</li></ul><h1 id=podman>Podman</h1><p><a href=https://docs.podman.io/en/latest/>Podman</a> est un outil sans démon, open-source, natif Linux, conçu pour faciliter la recherche, l&rsquo;exécution, la construction, le partage et le déploiement d&rsquo;applications en utilisant les conteneurs et les Images de Conteneur <a href=https://opencontainers.org/>Open Containers Initiative (OCI)</a>.</p><p><a href=https://docs.podman.io/en/latest/>Podman</a> propose une ligne de commande (CLI) familière aux utilisateurs de l&rsquo;outil Docker.</p><p><a href=https://docs.podman.io/en/latest/>Podman</a> gère l&rsquo;ensemble de l&rsquo;écosystème de conteneurs, qui inclut les pods, les conteneurs, les images de conteneurs et les volumes, en utilisant la bibliothèque <a href=https://github.com/containers/podman>libpod</a>.</p><p>Concepts fondamentaux :</p><ul><li>Un pod est un groupe de conteneurs qui fonctionnent ensemble et partagent les mêmes ressources, similaire aux pods Kubernetes.</li><li>Un conteneur est un environnement isolé dans lequel une application peut fonctionner sans affecter le reste du système ou être influencé par celui-ci.</li><li>Une image de conteneur est un fichier statique contenant du code exécutable qui peut créer un conteneur sur un système informatique. Une image de conteneur est immuable – cela signifie qu&rsquo;elle ne peut pas être modifiée et peut être déployée de manière cohérente dans n&rsquo;importe quel environnement.</li><li>Un volume de conteneur est un stockage durable qui peut être utilisé par un conteneur.</li></ul><p><em>Attention : Pour obtenir une performance optimale, je vous recommande d&rsquo;utiliser le <a href=https://docs.nvidia.com/ai-enterprise/deployment-guide-rhel-with-kvm/0.1.0/podman.html>GPU Passthrough</a>.</em></p><h1 id=vs-code>VS Code</h1><p><a href=https://code.visualstudio.com/>VS Code</a> est un éditeur de code extensible et multi-plateformes développé par Microsoft.</p><p><a href=https://code.visualstudio.com/>VS Code</a> peut être étendu via des extensions disponibles dans un <a href=https://marketplace.visualstudio.com/vscode>dépôt central</a>.</p><p><a href=https://www.continue.dev/>Continue</a> est un assistant de code AI open-source qui permet de connecter n&rsquo;importe quels modèles à un IDE.</p><p>Nous utiliserons l&rsquo;extension <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">VS Code Continue</a> pour travailler avec notre configuration <a href=https://ollama.com/>Ollama</a> (locale ou distante). En outre, vous pouvez utiliser différents fournisseurs et services, tels que <a href=https://openai.com/>Open AI</a>, <a href=https://www.anthropic.com/>Anthropic</a>, <a href=https://mistral.ai/>Mistral</a>, <a href=https://gemini.google.com/>Gemini</a>, et d&rsquo;autres.</p><h2 id=installation-de-lextension>Installation de l&rsquo;extension</h2><p>Les étapes à suivre :</p><ol><li>Ouvrez VS Code</li><li>Cliquez sur le menu &ldquo;extensions&rdquo; dans le panneau à gauche</li><li>Filtrez les résultats avec le terme <code>Continue.continue</code></li></ol><p><a href=/blog/web/20240724_ollama_locally_p1.png><img alt=continue_step_1 src=/blog/web/20240724_ollama_locally_p1.png></a></p><ol start=4><li>Installez l&rsquo;extension nommée &ldquo;Continue - Codestral, Claude, and more&rdquo;</li><li>Sélectionnez l&rsquo;icone Continue dans le panneau de gauche</li></ol><p><a href=/blog/web/20240724_ollama_locally_p2.png><img alt=continue_step_2 src=/blog/web/20240724_ollama_locally_p2.png></a></p><h2 id=configuration-de-lextension-vs-code-continue>Configuration de l&rsquo;extension VS Code Continue</h2><p>Vous pouvez accéder au fichier <code>config.json</code> de deux manières différentes.</p><p>Première manière par l&rsquo;interface de VS Code :</p><ol><li>Ouvrez VS Code</li><li>Cliquez sur le menu Continue dans le panneau de gauche</li><li>Cliquez sur l&rsquo;option Configure Continue en bas à droite du nouveau panneau de gauche</li></ol><p><a href=/blog/web/20240724_ollama_locally_p3.png><img alt=continue_step_3 src=/blog/web/20240724_ollama_locally_p3.png></a></p><p>Seconde manière par la Palette de commande de VS Code :</p><ol><li>Ouvrez VS Code</li><li>Ouvrez la Palette de commande avec la combinaison <code>Ctrl + Shift + p</code></li><li>Utilisez le terme <code>continue option</code> dans l&rsquo;espace de recherche et sélectionnez l&rsquo;option <code>Continue : open config.json</code></li></ol><p><a href=/blog/web/20240724_ollama_locally_p4.png><img alt=continue_step_4 src=/blog/web/20240724_ollama_locally_p4.png></a></p><h1 id=configuration-locale>Configuration locale</h1><h2 id=mise-en-place-de-ollama-en-locale>Mise en place de Ollama en locale</h2><p>Nous utiliserons les paramètres suivantes :</p><ul><li>Modèle Ollama : <code>llama3:8b</code></li></ul><p>Pour installer et utiliser <a href=https://ollama.com/>Ollama</a> :</p><ol><li>Allez sur le <a href=https://ollama.com/download>site officiel</a> et télécharger la version souhaitée (Linux, Windows or Mac).</li><li>Suivez les instructions d&rsquo;installation de l&rsquo;outil</li><li>Ouvrez un terminal</li><li>Exécutez la commande : <code>Ollama pull llama3:8b</code> <em>(Ou choisissez le model souhaité à partir de la librarie Ollama)</em></li><li>Exécutez la commande : <code>Ollama run llama3:8b</code></li></ol><p><em>Note : Si vous n&rsquo;avez pas de GPU, alors <a href=https://ollama.com/>Ollama</a> affichera le warning suivant : <code>No NVIDIA/AMD GPU detected. Ollama will run in CPU-only mode.</code></em>
<em>Note : utilisez la commande <code>/bye</code> pour terminer le prompt</em></p><p><a href=/blog/web/20240724_ollama_locally_p5.png><img alt=ollama_local_step_1 src=/blog/web/20240724_ollama_locally_p5.png></a></p><h2 id=configuration-de-lextension-vs-code-continue-1>Configuration de l&rsquo;extension VS Code Continue</h2><p>Exemple d&rsquo;une configuration de <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">VS Code Continue</a> pour utiliser un serveur locale de <a href=https://ollama.com/>Ollama</a> :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-JSON data-lang=JSON><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span>{
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span>  <span style=color:#ff79c6>&#34;models&#34;</span>: [
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span>    {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span>      <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;CodeLlama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>      <span style=color:#ff79c6>&#34;provider&#34;</span> : <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>      <span style=color:#ff79c6>&#34;model&#34;</span> : <span style=color:#f1fa8c>&#34;codellama:7b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span>    },
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>    {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>      <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Llama3&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span>      <span style=color:#ff79c6>&#34;provider&#34;</span> : <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>      <span style=color:#ff79c6>&#34;model&#34;</span> : <span style=color:#f1fa8c>&#34;llama3:8b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>    }
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13</span><span>  ],
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14</span><span>  <span style=color:#ff79c6>&#34;tabAutocompleteModel&#34;</span>: {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15</span><span>    <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Starcoder&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16</span><span>    <span style=color:#ff79c6>&#34;provider&#34;</span>: <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17</span><span>    <span style=color:#ff79c6>&#34;model&#34;</span>: <span style=color:#f1fa8c>&#34;starcoder2:3b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18</span><span>  },
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19</span><span>  <span style=color:#ff79c6>&#34;embeddingsProvider&#34;</span>: {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20</span><span>    <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Nomic&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21</span><span>    <span style=color:#ff79c6>&#34;provider&#34;</span>: <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22</span><span>    <span style=color:#ff79c6>&#34;model&#34;</span>: <span style=color:#f1fa8c>&#34;nomic-embed-text&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23</span><span>  }
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24</span><span>}
</span></span></code></pre></div><h1 id=configuration-distante>Configuration distante</h1><h2 id=mise-en-place-de-ollama-avec-podman>Mise en place de Ollama avec Podman</h2><p><strong>Objectif :</strong> Déployer <a href=https://ollama.com/>Ollama</a> sur n&rsquo;importe quel machine, et plus particulièrement sur une machine avec un ou plusieurs GPU récents, permettant une utilisation optimale à partir de tout ordinateur connecté au même réseau.</p><p>Nous utiliserons les paramètres suivants :</p><ul><li>Nom du pod : <code>llms-pod</code></li><li>Nom du conteneur : <code>llms-pod-ollama</code></li><li>Modèle <a href=https://ollama.com/>Ollama</a> : <code>llama3:8b</code></li><li>Numéro du port par défaut : <code>11434</code></li></ul><p>Les étapes à suivre sont les suivantes :</p><ol><li>Création d&rsquo;un pod avec la définition du port (API) : <code>podman pod create --name llms-pod -p 11434:11434</code></li><li>Création d&rsquo;un conteneur dans le pod créé : <code>podman run -dt --pod llms-pod --name llms-pod-ollama docker.io/ollama/ollama:latest</code></li><li>Récupération d&rsquo;un modèle spécifique : <code>podman exec -it llms-pod-ollama ollama pull llama3:8b</code></li><li>Exécution d&rsquo;un modèle spécifique : <code>podman exec -it llms-pod-ollama ollama run llama3:8b</code> `</li></ol><p><em>Note : Vous trouverez des scripts pour gérer le pod plus facilement dans ce <a href=https://github.com/pragmatias/ollama_local>dépôt github</a>.</em></p><p><a href=/blog/web/20240724_ollama_locally_p6.png><img alt=ollama_local_step_2 src=/blog/web/20240724_ollama_locally_p6.png></a></p><h2 id=configuration-de-lextension-vs-code-continue-2>Configuration de l&rsquo;extension VS Code Continue</h2><p>Exemple d&rsquo;une configuration de <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">VS Code Continue</a> pour utiliser un serveur distant de <a href=https://ollama.com/>Ollama</a> :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-JSON data-lang=JSON><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span>{
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span>  <span style=color:#ff79c6>&#34;models&#34;</span>: [
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span>    {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span>      <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;CodeLlama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>      <span style=color:#ff79c6>&#34;provider&#34;</span> : <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>      <span style=color:#ff79c6>&#34;model&#34;</span> : <span style=color:#f1fa8c>&#34;codellama:7b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span>      <span style=color:#ff79c6>&#34;apiBase&#34;</span>: <span style=color:#f1fa8c>&#34;http://localhost:11434&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>    },
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>    {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span>      <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Llama3&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>      <span style=color:#ff79c6>&#34;provider&#34;</span> : <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>      <span style=color:#ff79c6>&#34;model&#34;</span> : <span style=color:#f1fa8c>&#34;llama3:8b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13</span><span>      <span style=color:#ff79c6>&#34;apiBase&#34;</span>: <span style=color:#f1fa8c>&#34;http://localhost:11434&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14</span><span>    }
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15</span><span>  ],
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16</span><span>  <span style=color:#ff79c6>&#34;tabAutocompleteModel&#34;</span>: {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17</span><span>    <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Starcoder&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18</span><span>    <span style=color:#ff79c6>&#34;provider&#34;</span>: <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19</span><span>    <span style=color:#ff79c6>&#34;model&#34;</span>: <span style=color:#f1fa8c>&#34;starcoder2:3b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20</span><span>    <span style=color:#ff79c6>&#34;apiBase&#34;</span>: <span style=color:#f1fa8c>&#34;http://localhost:11434&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21</span><span>  },
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22</span><span>  <span style=color:#ff79c6>&#34;embeddingsProvider&#34;</span>: {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23</span><span>    <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Nomic&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24</span><span>    <span style=color:#ff79c6>&#34;provider&#34;</span>: <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25</span><span>    <span style=color:#ff79c6>&#34;model&#34;</span>: <span style=color:#f1fa8c>&#34;nomic-embed-text&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26</span><span>    <span style=color:#ff79c6>&#34;apiBase&#34;</span>: <span style=color:#f1fa8c>&#34;http://localhost:11434&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27</span><span>  }
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28</span><span>}
</span></span></code></pre></div><h1 id=conclusion>Conclusion</h1><p>Il est très facile d&rsquo;utiliser des <a href=https://en.wikipedia.org/wiki/Large_language_model>LLMs</a> localement, pour toutes les personnes ayant une attention particulière concernant l&rsquo;usage de leurs données (vie privée, données sensibles, &mldr;) ou n&rsquo;ayant pas les moyens d&rsquo;utiliser les offres commerciales, avec <a href=https://ollama.com/>Ollama</a> <em>(disponible sur les plateformes Linux, Windows et Mac)</em> et <a href=https://code.visualstudio.com/>VS Code</a>.
Cependant, il est indispensable d&rsquo;avoir un GPU récent et une quantité de mémoire suffisante pour pouvoir l&rsquo;utiliser efficacement.</p></div></article></div></div><footer><div class="container-fluid prag-bg-primary prag-foot">Généré avec <a href=https://gohugo.io/>Hugo</a>
&nbsp; - &nbsp;
<a href=https://en.wikipedia.org/wiki/WTFPL>WTFPL license</a> © 2018–2024</div></footer></body></html>