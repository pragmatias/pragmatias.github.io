<!doctype html><html lang=fr><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta charset=utf-8><meta name=robots content="noindex, nofollow, noarchive, nosnipper, noodp, noydir"><meta name=google content="notranslate, noimageindex"><meta name=slurp content="notranslate, noimageindex"><meta name=msnbot content="notranslate, noimageindex"><meta name=bingbot content="notranslate, noimageindex"><meta name=generator content="Hugo 0.129.0"><link rel=stylesheet href=https://www.pragmatias.fr//css/bootstrap.min.css><link rel=stylesheet href=https://www.pragmatias.fr//css/pragmatias.css><script src=https://www.pragmatias.fr//js/jquery-3.6.0.slim.min.js></script><script src=https://www.pragmatias.fr//js/popper.min.js></script><script src=https://www.pragmatias.fr//js/bootstrap.bundle.min.js></script><link rel=alternate type=application/rss+xml href=https://www.pragmatias.fr/feed.xml><title>LLMs : Utilisation de Ollama avec Podman et VS Code</title><body><div class="navbar navbar-expand-md prag-bg-primary prag-header" role=navigation><div class="container-fluid justify-content-center"><div class=navbar-brand><a href=https://www.pragmatias.fr/blog/><img src=/images/logo_pragmatias.svg alt=pragmatias></a></div><button class="navbar-toggler justify-content-end prag-navbar" type=button data-toggle=collapse data-target=#navbarSupportedContent1,#navbarSupportedContent2 aria-controls=navbarSupportedContent1 aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent1><ul class="navbar-nav text-center"><li class=nav-item><a class=nav-link href=https://www.pragmatias.fr/blog/>Blog</a></li><li class=nav-item><a class=nav-link href=https://www.pragmatias.fr/tags/>Tags</a></li><li class=nav-item><a class=nav-link href=https://www.pragmatias.fr/archives/>Archives</a></li></ul></div><div class="collapse navbar-collapse justify-content-md-end" id=navbarSupportedContent2><ul class="navbar-nav flex-row justify-content-center"><li class=nav-item><a href=https://www.pragmatias.fr/en/2024/07/24/llms-using-ollama-with-podman-and-vs-code/ class="prag_header_svg mr-1 ml-1"><img src=/images/united-kingdom-flag-round-xs-24.png alt=English></a></li><li class=nav-item><a href=https://www.pragmatias.fr/feed.xml title="Pragmatias Blog" class="prag_header_svg mr-1 ml-1"><svg height="24" style="enable-background:new 0 0 508.52 508.52" viewBox="0 0 508.52 508.52" width="24" xmlns:xlink="http://www.w3.org/1999/xlink"><path style="fill-rule:evenodd;clip-rule:evenodd;fill:" d="M254.26.0C113.845.0.0 113.845.0 254.26s113.845 254.26 254.26 254.26 254.26-113.845 254.26-254.26C508.52 113.813 394.675.0 254.26.0zM137.141 412.441c-22.852.0-41.413-18.434-41.413-41.285.0-22.693 18.561-41.349 41.413-41.349 22.915.0 41.444 18.656 41.476 41.349C178.618 393.976 160.088 412.441 137.141 412.441zM241.197 412.791c0-39.029-15.16-75.674-42.62-103.071-27.46-27.524-63.978-42.716-102.785-42.716V207.38c113.177.0 205.315 92.137 205.315 205.41h-59.91zM347.001 412.727c0-138.603-112.669-251.399-251.145-251.399v-59.624c171.435.0 310.96 139.589 310.96 311.023H347.001z"/></svg></a></li><li class=nav-item><a href=mailto:contact@pragmatias.fr title=Mail class="prag_header_svg mr-1 ml-1"><svg height="24" style="enable-background:new 0 0 299.997 299.997" viewBox="0 0 299.997 299.997" width="24" xmlns:xlink="http://www.w3.org/1999/xlink"><path style="fill-rule:evenodd;clip-rule:evenodd;fill:" d="M149.996.0C67.157.0.001 67.158.001 149.997c0 82.837 67.156 150 149.995 150s150-67.163 150-150C299.996 67.158 232.835.0 149.996.0zM149.999 52.686l88.763 55.35H61.236l88.763-55.35zm89.869 143.737h-.009c0 8.878-7.195 16.072-16.072 16.072H76.211c-8.878.0-16.072-7.195-16.072-16.072v-84.865c0-.939.096-1.852.252-2.749l84.808 52.883c.104.065.215.109.322.169.112.062.226.122.34.179.599.309 1.216.558 1.847.721.065.018.13.026.195.041.692.163 1.393.265 2.093.265h.005c.005.0.01.0.01.0.7.0 1.401-.099 2.093-.265.065-.016.13-.023.195-.041.63-.163 1.245-.412 1.847-.721.114-.057.228-.117.34-.179.106-.06.218-.104.322-.169l84.808-52.883c.156.897.252 1.808.252 2.749v84.865z"/></svg></a></li><li><a href=https://github.com/pragmatias/ title=github class="prag_header_svg mr-1 ml-1"><svg height="24" style="enable-background:new 0 0 438.549 438.549" viewBox="0 0 438.549 438.549" width="24" xmlns:xlink="http://www.w3.org/1999/xlink"><path style="fill-rule:evenodd;clip-rule:evenodd;fill:" d="M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8C295.736 15.166 259.057 5.365 219.271 5.365c-39.781.0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168.0 184.854.0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562.0-.571-.049-5.708-.144-15.417-.098-9.709-.144-18.179-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289s4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136s11.704-.476 16.274-1.423c4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826.0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817.0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906C438.536 184.851 428.728 148.168 409.132 114.573z"/></svg></a></li></ul></div></div></div><div id=content><div class=container-fluid><article class="blog-post blog-post-with-toc"><header><h2 class=blog-post-title>LLMs : Utilisation de Ollama avec Podman et VS Code</h2><div class=blog-post-date><span>Derni√®re modification : 24 Juillet 2024</span></div><div class=blog-post-date>Temps de lecture : 6 minute(s) - 1143 mots</div><div class=blog-post-tags><strong>Tags:</strong>
<a href=https://www.pragmatias.fr/tags/ollama/>Ollama</a>
<a href=https://www.pragmatias.fr/tags/llms/>LLMs</a>
<a href=https://www.pragmatias.fr/tags/vs-code/>VS Code</a>
<a href=https://www.pragmatias.fr/tags/podman/>Podman</a></div></header><aside class=prag-toc><h1 class=prag-toc-head>Sommaire</h1><div class=prag-toc-body><nav id=TableOfContents><ol><li><a href=#ollama>Ollama</a></li><li><a href=#podman>Podman</a></li><li><a href=#vs-code>VS Code</a><ol><li><a href=#installation-de-lextension>Installation de l&rsquo;extension</a></li><li><a href=#configuration-de-lextension-vs-code-continue>Configuration de l&rsquo;extension VS Code Continue</a></li></ol></li><li><a href=#configuration-locale>Configuration locale</a><ol><li><a href=#mise-en-place-de-ollama-en-locale>Mise en place de Ollama en locale</a></li><li><a href=#configuration-de-lextension-vs-code-continue-1>Configuration de l&rsquo;extension VS Code Continue</a></li></ol></li><li><a href=#configuration-distante>Configuration distante</a><ol><li><a href=#mise-en-place-de-ollama-avec-podman>Mise en place de Ollama avec Podman</a></li><li><a href=#configuration-de-lextension-vs-code-continue-2>Configuration de l&rsquo;extension VS Code Continue</a></li></ol></li><li><a href=#conclusion>Conclusion</a></li></ol></nav></div></aside><a id=showTopBtn href=# class=prag-sticky-bot><svg height="24" id="Layer_1" style="enable-background:new 0 0 438.533 438.533" viewBox="0 0 438.533 438.533" width="24" xmlns:xlink="http://www.w3.org/1999/xlink"><path style="fill-rule:evenodd;clip-rule:evenodd;fill:" d="M409.133 109.203c-19.608-33.592-46.205-60.189-79.798-79.796C295.736 9.801 259.058.0 219.273.0c-39.781.0-76.47 9.801-110.063 29.407-33.595 19.604-60.192 46.201-79.8 79.796C9.801 142.8.0 179.489.0 219.267c0 39.78 9.804 76.463 29.407 110.062 19.607 33.592 46.204 60.189 79.799 79.798 33.597 19.605 70.283 29.407 110.063 29.407s76.47-9.802 110.065-29.407c33.593-19.602 60.189-46.206 79.795-79.798 19.603-33.596 29.403-70.284 29.403-110.062C438.533 179.485 428.732 142.795 409.133 109.203zM361.449 231.831l-25.981 25.981c-3.613 3.613-7.901 5.42-12.847 5.42-4.948.0-9.229-1.807-12.847-5.42l-53.954-53.961v143.32c0 4.948-1.813 9.232-5.428 12.847-3.613 3.62-7.898 5.427-12.847 5.427h-36.547c-4.948.0-9.231-1.807-12.847-5.427-3.617-3.614-5.426-7.898-5.426-12.847v-143.32l-53.959 53.961c-3.431 3.425-7.708 5.133-12.85 5.133-5.14.0-9.423-1.708-12.85-5.133l-25.981-25.981c-3.422-3.429-5.137-7.714-5.137-12.852.0-5.137 1.709-9.419 5.137-12.847l103.356-103.353 25.981-25.981c3.427-3.425 7.71-5.14 12.847-5.14 5.142.0 9.423 1.715 12.849 5.14l25.98 25.981 103.35 103.353c3.432 3.427 5.14 7.71 5.14 12.847C366.589 224.117 364.881 228.402 361.449 231.831z"/></svg>
</a><script>$(document).ready(function(){$("#showTopBtn").removeClass("prag-sticky-bot"),$("#showTopBtn").addClass("prag-sticky-hide"),$(function(){$(window).scroll(function(){$(this).scrollTop()>900?($("#showTopBtn").addClass("prag-sticky-bot"),$("#showTopBtn").removeClass("prag-sticky-hide")):($("#showTopBtn").addClass("prag-sticky-hide"),$("#showTopBtn").removeClass("prag-sticky-bot"))})})})</script><div class=blog-post-main><p>Vous trouverez dans cet article, des informations pour utiliser <a href=https://ollama.com/>Ollama</a> (<a href=https://en.wikipedia.org/wiki/Large_language_model>LLMs</a>) avec <a href=https://podman.io/>Podman</a> et <a href=https://code.visualstudio.com/>VS Code</a>.</p><h1 id=ollama>Ollama</h1><p><a href=https://ollama.com/>Ollama</a> est un outil gratuit et open-source con√ßu pour ex√©cuter localement des <a href=https://en.wikipedia.org/wiki/Large_language_model>LLMs (Large Language Models)</a> libre sur votre syst√®me.</p><p><a href=https://ollama.com/>Ollama</a> est con√ßu pour tirer avantage des cartes graphiques Nvidia ou AMD. Si vous n&rsquo;avez qu&rsquo;un CPU, vous aurez une tr√®s mauvaise performance du mod√®le.</p><p>Vous trouverez la liste des GPU prises en charge dans la <a href=https://github.com/ollama/ollama/blob/main/docs/gpu.md>documentation officielle</a>.</p><p>Il est n√©cessaire d&rsquo;avoir une quantit√© importante de m√©moire pour l&rsquo;utiliser. Je vous recommande de disposer d&rsquo;au moins 32 Go.</p><p>Vous trouverez tous les mod√®les LLM disponibles dans la <a href=https://ollama.com/library>biblioth√®que officielle</a>.</p><p>Quelques exemples de mod√®les disponibles :</p><ul><li><a href=https://ollama.com/library/llama3>llama3</a> : Meta Llama 3, une famille de mod√®les d√©velopp√©e par Meta Inc.</li><li><a href=https://ollama.com/library/codellama>codellama</a> : Code Llama est un mod√®le con√ßu pour g√©n√©rer et discuter du code, construit sur la base de Llama 2.</li><li><a href=https://ollama.com/library/gemma2>gemma2</a> : Google Gemma 2, pr√©sentant une nouvelle architecture con√ßue pour offrir des performances et une efficacit√© exceptionnelles.</li><li><a href=https://ollama.com/library/codegemma>codegemma</a> : CodeGemma est un ensemble de mod√®les puissants et l√©gers qui peuvent accomplir diverses t√¢ches de codage, telles que la finition automatique du code, la g√©n√©ration de code, la compr√©hension naturelle du langage, la raison math√©matique et l&rsquo;ex√©cution d&rsquo;instructions.</li><li><a href=https://ollama.com/library/starcoder2>starcoder2</a> : StarCoder2 est la prochaine g√©n√©ration de mod√®les decode ouverts entra√Æn√©s de mani√®re transparente.</li></ul><h1 id=podman>Podman</h1><p><a href=https://docs.podman.io/en/latest/>Podman</a> est un outil sans d√©mon, open-source, natif Linux, con√ßu pour faciliter la recherche, l&rsquo;ex√©cution, la construction, le partage et le d√©ploiement d&rsquo;applications en utilisant les conteneurs et les Images de Conteneur <a href=https://opencontainers.org/>Open Containers Initiative (OCI)</a>.</p><p><a href=https://docs.podman.io/en/latest/>Podman</a> propose une ligne de commande (CLI) famili√®re aux utilisateurs de l&rsquo;outil Docker.</p><p><a href=https://docs.podman.io/en/latest/>Podman</a> g√®re l&rsquo;ensemble de l&rsquo;√©cosyst√®me de conteneurs, qui inclut les pods, les conteneurs, les images de conteneurs et les volumes, en utilisant la biblioth√®que <a href=https://github.com/containers/podman>libpod</a>.</p><p>Concepts fondamentaux :</p><ul><li>Un pod est un groupe de conteneurs qui fonctionnent ensemble et partagent les m√™mes ressources, similaire aux pods Kubernetes.</li><li>Un conteneur est un environnement isol√© dans lequel une application peut fonctionner sans affecter le reste du syst√®me ou √™tre influenc√© par celui-ci.</li><li>Une image de conteneur est un fichier statique contenant du code ex√©cutable qui peut cr√©er un conteneur sur un syst√®me informatique. Une image de conteneur est immuable ‚Äì cela signifie qu&rsquo;elle ne peut pas √™tre modifi√©e et peut √™tre d√©ploy√©e de mani√®re coh√©rente dans n&rsquo;importe quel environnement.</li><li>Un volume de conteneur est un stockage durable qui peut √™tre utilis√© par un conteneur.</li></ul><p><em>Attention : Pour obtenir une performance optimale, je vous recommande d&rsquo;utiliser le <a href=https://docs.nvidia.com/ai-enterprise/deployment-guide-rhel-with-kvm/0.1.0/podman.html>GPU Passthrough</a>.</em></p><h1 id=vs-code>VS Code</h1><p><a href=https://code.visualstudio.com/>VS Code</a> est un √©diteur de code extensible et multi-plateformes d√©velopp√© par Microsoft.</p><p><a href=https://code.visualstudio.com/>VS Code</a> peut √™tre √©tendu via des extensions disponibles dans un <a href=https://marketplace.visualstudio.com/vscode>d√©p√¥t central</a>.</p><p><a href=https://www.continue.dev/>Continue</a> est un assistant de code AI open-source qui permet de connecter n&rsquo;importe quels mod√®les √† un IDE.</p><p>Nous utiliserons l&rsquo;extension <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">VS Code Continue</a> pour travailler avec notre configuration <a href=https://ollama.com/>Ollama</a> (locale ou distante). En outre, vous pouvez utiliser diff√©rents fournisseurs et services, tels que <a href=https://openai.com/>Open AI</a>, <a href=https://www.anthropic.com/>Anthropic</a>, <a href=https://mistral.ai/>Mistral</a>, <a href=https://gemini.google.com/>Gemini</a>, et d&rsquo;autres.</p><h2 id=installation-de-lextension>Installation de l&rsquo;extension</h2><p>Les √©tapes √† suivre :</p><ol><li>Ouvrez VS Code</li><li>Cliquez sur le menu &ldquo;extensions&rdquo; dans le panneau √† gauche</li><li>Filtrez les r√©sultats avec le terme <code>Continue.continue</code></li></ol><p><a href=/blog/web/20240724_ollama_locally_p1.png><img alt=continue_step_1 src=/blog/web/20240724_ollama_locally_p1.png></a></p><ol start=4><li>Installez l&rsquo;extension nomm√©e &ldquo;Continue - Codestral, Claude, and more&rdquo;</li><li>S√©lectionnez l&rsquo;icone Continue dans le panneau de gauche</li></ol><p><a href=/blog/web/20240724_ollama_locally_p2.png><img alt=continue_step_2 src=/blog/web/20240724_ollama_locally_p2.png></a></p><h2 id=configuration-de-lextension-vs-code-continue>Configuration de l&rsquo;extension VS Code Continue</h2><p>Vous pouvez acc√©der au fichier <code>config.json</code> de deux mani√®res diff√©rentes.</p><p>Premi√®re mani√®re par l&rsquo;interface de VS Code :</p><ol><li>Ouvrez VS Code</li><li>Cliquez sur le menu Continue dans le panneau de gauche</li><li>Cliquez sur l&rsquo;option Configure Continue en bas √† droite du nouveau panneau de gauche</li></ol><p><a href=/blog/web/20240724_ollama_locally_p3.png><img alt=continue_step_3 src=/blog/web/20240724_ollama_locally_p3.png></a></p><p>Seconde mani√®re par la Palette de commande de VS Code :</p><ol><li>Ouvrez VS Code</li><li>Ouvrez la Palette de commande avec la combinaison <code>Ctrl + Shift + p</code></li><li>Utilisez le terme <code>continue option</code> dans l&rsquo;espace de recherche et s√©lectionnez l&rsquo;option <code>Continue : open config.json</code></li></ol><p><a href=/blog/web/20240724_ollama_locally_p4.png><img alt=continue_step_4 src=/blog/web/20240724_ollama_locally_p4.png></a></p><h1 id=configuration-locale>Configuration locale</h1><h2 id=mise-en-place-de-ollama-en-locale>Mise en place de Ollama en locale</h2><p>Nous utiliserons les param√®tres suivantes :</p><ul><li>Mod√®le Ollama : <code>llama3:8b</code></li></ul><p>Pour installer et utiliser <a href=https://ollama.com/>Ollama</a> :</p><ol><li>Allez sur le <a href=https://ollama.com/download>site officiel</a> et t√©l√©charger la version souhait√©e (Linux, Windows or Mac).</li><li>Suivez les instructions d&rsquo;installation de l&rsquo;outil</li><li>Ouvrez un terminal</li><li>Ex√©cutez la commande : <code>Ollama pull llama3:8b</code> <em>(Ou choisissez le model souhait√© √† partir de la librarie Ollama)</em></li><li>Ex√©cutez la commande : <code>Ollama run llama3:8b</code></li></ol><p><em>Note : Si vous n&rsquo;avez pas de GPU, alors <a href=https://ollama.com/>Ollama</a> affichera le warning suivant : <code>No NVIDIA/AMD GPU detected. Ollama will run in CPU-only mode.</code></em>
<em>Note : utilisez la commande <code>/bye</code> pour terminer le prompt</em></p><p><a href=/blog/web/20240724_ollama_locally_p5.png><img alt=ollama_local_step_1 src=/blog/web/20240724_ollama_locally_p5.png></a></p><h2 id=configuration-de-lextension-vs-code-continue-1>Configuration de l&rsquo;extension VS Code Continue</h2><p>Exemple d&rsquo;une configuration de <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">VS Code Continue</a> pour utiliser un serveur locale de <a href=https://ollama.com/>Ollama</a> :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-JSON data-lang=JSON><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span>{
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span>  <span style=color:#ff79c6>&#34;models&#34;</span>: [
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span>    {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span>      <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;CodeLlama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>      <span style=color:#ff79c6>&#34;provider&#34;</span> : <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>      <span style=color:#ff79c6>&#34;model&#34;</span> : <span style=color:#f1fa8c>&#34;codellama:7b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span>    },
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>    {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>      <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Llama3&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span>      <span style=color:#ff79c6>&#34;provider&#34;</span> : <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>      <span style=color:#ff79c6>&#34;model&#34;</span> : <span style=color:#f1fa8c>&#34;llama3:8b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>    }
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13</span><span>  ],
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14</span><span>  <span style=color:#ff79c6>&#34;tabAutocompleteModel&#34;</span>: {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15</span><span>    <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Starcoder&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16</span><span>    <span style=color:#ff79c6>&#34;provider&#34;</span>: <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17</span><span>    <span style=color:#ff79c6>&#34;model&#34;</span>: <span style=color:#f1fa8c>&#34;starcoder2:3b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18</span><span>  },
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19</span><span>  <span style=color:#ff79c6>&#34;embeddingsProvider&#34;</span>: {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20</span><span>    <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Nomic&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21</span><span>    <span style=color:#ff79c6>&#34;provider&#34;</span>: <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22</span><span>    <span style=color:#ff79c6>&#34;model&#34;</span>: <span style=color:#f1fa8c>&#34;nomic-embed-text&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23</span><span>  }
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24</span><span>}
</span></span></code></pre></div><h1 id=configuration-distante>Configuration distante</h1><h2 id=mise-en-place-de-ollama-avec-podman>Mise en place de Ollama avec Podman</h2><p><strong>Objectif :</strong> D√©ployer <a href=https://ollama.com/>Ollama</a> sur n&rsquo;importe quel machine, et plus particuli√®rement sur une machine avec un ou plusieurs GPU r√©cents, permettant une utilisation optimale √† partir de tout ordinateur connect√© au m√™me r√©seau.</p><p>Nous utiliserons les param√®tres suivants :</p><ul><li>Nom du pod : <code>llms-pod</code></li><li>Nom du conteneur : <code>llms-pod-ollama</code></li><li>Mod√®le <a href=https://ollama.com/>Ollama</a> : <code>llama3:8b</code></li><li>Num√©ro du port par d√©faut : <code>11434</code></li></ul><p>Les √©tapes √† suivre sont les suivantes :</p><ol><li>Cr√©ation d&rsquo;un pod avec la d√©finition du port (API) : <code>podman pod create --name llms-pod -p 11434:11434</code></li><li>Cr√©ation d&rsquo;un conteneur dans le pod cr√©√© : <code>podman run -dt --pod llms-pod --name llms-pod-ollama docker.io/ollama/ollama:latest</code></li><li>R√©cup√©ration d&rsquo;un mod√®le sp√©cifique : <code>podman exec -it llms-pod-ollama ollama pull llama3:8b</code></li><li>Ex√©cution d&rsquo;un mod√®le sp√©cifique : <code>podman exec -it llms-pod-ollama ollama run llama3:8b</code> `</li></ol><p><em>Note : Vous trouverez des scripts pour g√©rer le pod plus facilement dans ce <a href=https://github.com/pragmatias/ollama_local>d√©p√¥t github</a>.</em></p><p><a href=/blog/web/20240724_ollama_locally_p6.png><img alt=ollama_local_step_2 src=/blog/web/20240724_ollama_locally_p6.png></a></p><h2 id=configuration-de-lextension-vs-code-continue-2>Configuration de l&rsquo;extension VS Code Continue</h2><p>Exemple d&rsquo;une configuration de <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">VS Code Continue</a> pour utiliser un serveur distant de <a href=https://ollama.com/>Ollama</a> :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-JSON data-lang=JSON><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span>{
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span>  <span style=color:#ff79c6>&#34;models&#34;</span>: [
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span>    {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span>      <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;CodeLlama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>      <span style=color:#ff79c6>&#34;provider&#34;</span> : <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>      <span style=color:#ff79c6>&#34;model&#34;</span> : <span style=color:#f1fa8c>&#34;codellama:7b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span>      <span style=color:#ff79c6>&#34;apiBase&#34;</span>: <span style=color:#f1fa8c>&#34;http://localhost:11434&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>    },
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>    {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span>      <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Llama3&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>      <span style=color:#ff79c6>&#34;provider&#34;</span> : <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>      <span style=color:#ff79c6>&#34;model&#34;</span> : <span style=color:#f1fa8c>&#34;llama3:8b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13</span><span>      <span style=color:#ff79c6>&#34;apiBase&#34;</span>: <span style=color:#f1fa8c>&#34;http://localhost:11434&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14</span><span>    }
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15</span><span>  ],
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16</span><span>  <span style=color:#ff79c6>&#34;tabAutocompleteModel&#34;</span>: {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17</span><span>    <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Starcoder&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18</span><span>    <span style=color:#ff79c6>&#34;provider&#34;</span>: <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19</span><span>    <span style=color:#ff79c6>&#34;model&#34;</span>: <span style=color:#f1fa8c>&#34;starcoder2:3b&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20</span><span>    <span style=color:#ff79c6>&#34;apiBase&#34;</span>: <span style=color:#f1fa8c>&#34;http://localhost:11434&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21</span><span>  },
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22</span><span>  <span style=color:#ff79c6>&#34;embeddingsProvider&#34;</span>: {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23</span><span>    <span style=color:#ff79c6>&#34;title&#34;</span>: <span style=color:#f1fa8c>&#34;Nomic&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24</span><span>    <span style=color:#ff79c6>&#34;provider&#34;</span>: <span style=color:#f1fa8c>&#34;ollama&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25</span><span>    <span style=color:#ff79c6>&#34;model&#34;</span>: <span style=color:#f1fa8c>&#34;nomic-embed-text&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26</span><span>    <span style=color:#ff79c6>&#34;apiBase&#34;</span>: <span style=color:#f1fa8c>&#34;http://localhost:11434&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27</span><span>  }
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28</span><span>}
</span></span></code></pre></div><h1 id=conclusion>Conclusion</h1><p>Il est tr√®s facile d&rsquo;utiliser des <a href=https://en.wikipedia.org/wiki/Large_language_model>LLMs</a> localement, pour toutes les personnes ayant une attention particuli√®re concernant l&rsquo;usage de leurs donn√©es (vie priv√©e, donn√©es sensibles, &mldr;) ou n&rsquo;ayant pas les moyens d&rsquo;utiliser les offres commerciales, avec <a href=https://ollama.com/>Ollama</a> <em>(disponible sur les plateformes Linux, Windows et Mac)</em> et <a href=https://code.visualstudio.com/>VS Code</a>.
Cependant, il est indispensable d&rsquo;avoir un GPU r√©cent et une quantit√© de m√©moire suffisante pour pouvoir l&rsquo;utiliser efficacement.</p></div></article></div></div><footer><div class="container-fluid prag-bg-primary prag-foot">G√©n√©r√© avec <a href=https://gohugo.io/>Hugo</a>
&nbsp; - &nbsp;
<a href=https://en.wikipedia.org/wiki/WTFPL>WTFPL license</a> ¬© 2018‚Äì2024</div></footer></body></html>